{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOSxbAssJ0Pq+5w72ywzEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Crisosth/IA/blob/main/AtividadeRNA_GustavoCrisosth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh0HSk9Z0ZpW"
      },
      "outputs": [],
      "source": [
        "#Importação da biblioteca pandas\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#base de dados =  previsores + classe\n",
        "\n",
        "#criação atributos previsores - 7 colunas x 900 registros\n",
        "previsores = pd.read_csv('passas_entradas.csv')\n",
        "\n",
        "#criação classe - 1 coluna x 900 registros\n",
        "classe = pd.read_csv('passas_saida.csv')"
      ],
      "metadata": {
        "id": "xyhAZH2g0oiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importação da função que faz a divisão da base de dados\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "jXEeCViM0qlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#divisão da base de dados - treinamento(70% = 630 registros) - teste (30% = 270 registros)\n",
        "#criação das variaveis que vão receber as partes da base de dados divididas\n",
        "#previsores_treinamento = 7 colunas x 630\n",
        "#previsores_teste = 7 colunas x 270 registros\n",
        "#classe_treinamento = 1 coluna x 630 registros\n",
        "#classe_teste = 1 coluna x 270 registros\n",
        "\n",
        "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.30)"
      ],
      "metadata": {
        "id": "FqOjErE70wcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores_treinamento"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sw4EHWVV0xew",
        "outputId": "2216ee88-c99d-43e9-fe4f-5cbc3f392fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
              "604   94211       450.004617       269.286569      0.801191       96340   \n",
              "322   67798       418.408134       207.825511      0.867919       69356   \n",
              "498   82886       424.822709       253.171548      0.803024       85879   \n",
              "753  124630       585.093803       275.493613      0.882211      128308   \n",
              "454   79055       395.368667       258.275952      0.757139       82562   \n",
              "..      ...              ...              ...           ...         ...   \n",
              "455   79057       436.390047       236.895393      0.839828       82642   \n",
              "203   57785       314.430977       236.183035      0.660138       58867   \n",
              "631   97583       522.786556       241.940773      0.886468      101231   \n",
              "843  166275       602.307775       356.236287      0.806340      168292   \n",
              "790  137583       649.541485       273.260282      0.907201      142650   \n",
              "\n",
              "       Extent  Perimeter  \n",
              "604  0.716848   1194.631  \n",
              "322  0.691027   1073.138  \n",
              "498  0.648281   1163.528  \n",
              "753  0.681832   1485.990  \n",
              "454  0.719506   1114.488  \n",
              "..        ...        ...  \n",
              "455  0.654597   1148.146  \n",
              "203  0.732866    903.769  \n",
              "631  0.725983   1298.731  \n",
              "843  0.719282   1580.961  \n",
              "790  0.731638   1590.354  \n",
              "\n",
              "[630 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91f2d3c4-a3e2-4c8e-8ffe-d3a3e77c533f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Perimeter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>94211</td>\n",
              "      <td>450.004617</td>\n",
              "      <td>269.286569</td>\n",
              "      <td>0.801191</td>\n",
              "      <td>96340</td>\n",
              "      <td>0.716848</td>\n",
              "      <td>1194.631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>67798</td>\n",
              "      <td>418.408134</td>\n",
              "      <td>207.825511</td>\n",
              "      <td>0.867919</td>\n",
              "      <td>69356</td>\n",
              "      <td>0.691027</td>\n",
              "      <td>1073.138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>82886</td>\n",
              "      <td>424.822709</td>\n",
              "      <td>253.171548</td>\n",
              "      <td>0.803024</td>\n",
              "      <td>85879</td>\n",
              "      <td>0.648281</td>\n",
              "      <td>1163.528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>124630</td>\n",
              "      <td>585.093803</td>\n",
              "      <td>275.493613</td>\n",
              "      <td>0.882211</td>\n",
              "      <td>128308</td>\n",
              "      <td>0.681832</td>\n",
              "      <td>1485.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>79055</td>\n",
              "      <td>395.368667</td>\n",
              "      <td>258.275952</td>\n",
              "      <td>0.757139</td>\n",
              "      <td>82562</td>\n",
              "      <td>0.719506</td>\n",
              "      <td>1114.488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>79057</td>\n",
              "      <td>436.390047</td>\n",
              "      <td>236.895393</td>\n",
              "      <td>0.839828</td>\n",
              "      <td>82642</td>\n",
              "      <td>0.654597</td>\n",
              "      <td>1148.146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>57785</td>\n",
              "      <td>314.430977</td>\n",
              "      <td>236.183035</td>\n",
              "      <td>0.660138</td>\n",
              "      <td>58867</td>\n",
              "      <td>0.732866</td>\n",
              "      <td>903.769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>97583</td>\n",
              "      <td>522.786556</td>\n",
              "      <td>241.940773</td>\n",
              "      <td>0.886468</td>\n",
              "      <td>101231</td>\n",
              "      <td>0.725983</td>\n",
              "      <td>1298.731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>843</th>\n",
              "      <td>166275</td>\n",
              "      <td>602.307775</td>\n",
              "      <td>356.236287</td>\n",
              "      <td>0.806340</td>\n",
              "      <td>168292</td>\n",
              "      <td>0.719282</td>\n",
              "      <td>1580.961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>137583</td>\n",
              "      <td>649.541485</td>\n",
              "      <td>273.260282</td>\n",
              "      <td>0.907201</td>\n",
              "      <td>142650</td>\n",
              "      <td>0.731638</td>\n",
              "      <td>1590.354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>630 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91f2d3c4-a3e2-4c8e-8ffe-d3a3e77c533f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91f2d3c4-a3e2-4c8e-8ffe-d3a3e77c533f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91f2d3c4-a3e2-4c8e-8ffe-d3a3e77c533f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-76554473-e336-4749-bb45-bc07432c878c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76554473-e336-4749-bb45-bc07432c878c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-76554473-e336-4749-bb45-bc07432c878c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "previsores_treinamento",
              "summary": "{\n  \"name\": \"previsores_treinamento\",\n  \"rows\": 630,\n  \"fields\": [\n    {\n      \"column\": \"Area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39687,\n        \"min\": 26908,\n        \"max\": 235047,\n        \"num_unique_values\": 630,\n        \"samples\": [\n          83555,\n          44081,\n          41995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MajorAxisLength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 118.50793398896099,\n        \"min\": 243.0382802,\n        \"max\": 997.2919406,\n        \"num_unique_values\": 630,\n        \"samples\": [\n          457.5464724,\n          328.5871474,\n          259.2088782\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MinorAxisLength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.377256849889186,\n        \"min\": 143.7108718,\n        \"max\": 492.2752785,\n        \"num_unique_values\": 630,\n        \"samples\": [\n          235.0998706,\n          173.3469657,\n          210.3507977\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Eccentricity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0908901529064262,\n        \"min\": 0.348729642,\n        \"max\": 0.96212444,\n        \"num_unique_values\": 630,\n        \"samples\": [\n          0.857893642,\n          0.849522441,\n          0.584337455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ConvexArea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41545,\n        \"min\": 28607,\n        \"max\": 278217,\n        \"num_unique_values\": 628,\n        \"samples\": [\n          195810,\n          80356,\n          82328\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05500256102415814,\n        \"min\": 0.379856115,\n        \"max\": 0.835454545,\n        \"num_unique_values\": 630,\n        \"samples\": [\n          0.711227443,\n          0.638466441,\n          0.729700613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Perimeter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 278.8114166813684,\n        \"min\": 678.815,\n        \"max\": 2697.753,\n        \"num_unique_values\": 630,\n        \"samples\": [\n          1159.779,\n          867.003,\n          801.526\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importação da biblioteca keras\n",
        "import keras\n",
        "\n",
        "# importação do modelo sequencial\n",
        "# sequencia de camadas: Entrada-Oculta-Saída\n",
        "from keras.models import Sequential\n",
        "\n",
        "# importação da classe de camadas densas\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "CL8Y1XhU0zOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando a rede neural do tipo sequencial(objeto)\n",
        "# nome = classificador\n",
        "classificador = Sequential()\n",
        "\n",
        "# adicionando a primeira camada oculta\n",
        "classificador.add(Dense(units= 32, activation= 'relu',\n",
        "                        kernel_initializer = 'random_uniform', input_dim= 7))\n",
        "# adicionando a segunda camada oculta\n",
        "classificador.add(Dense(units = 32, activation= 'relu', kernel_initializer= 'random_uniform'))\n",
        "\n",
        "# adicionando a terceira camada oculta\n",
        "classificador.add(Dense(units = 16, activation= 'relu', kernel_initializer= 'random_uniform'))"
      ],
      "metadata": {
        "id": "iTYTQ1Hw01WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adicionando a camada de saída\n",
        "classificador.add(Dense(units=1, activation= 'sigmoid'))"
      ],
      "metadata": {
        "id": "Zv2m1C6Y03_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compilando a rede neural com o metodo compile\n",
        "otimizador = keras.optimizers.Adam(learning_rate= 0.001, weight_decay= 0.0021, clipvalue=5.5)\n",
        "classificador.compile(optimizer = otimizador, loss= 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
        "#classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n"
      ],
      "metadata": {
        "id": "XUMFcbQm08uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# treinando a Rede Neural\n",
        "classificador.fit(previsores_treinamento, classe_treinamento, batch_size= 8, epochs = 190)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBFil1hg09JI",
        "outputId": "c2764442-89ce-4d69-b972-cb0b1055d683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/190\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.4369 - binary_accuracy: 0.8111\n",
            "Epoch 2/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4268 - binary_accuracy: 0.8365\n",
            "Epoch 3/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4881 - binary_accuracy: 0.8048\n",
            "Epoch 4/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8127\n",
            "Epoch 5/190\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.4267 - binary_accuracy: 0.8127\n",
            "Epoch 6/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4233 - binary_accuracy: 0.8302\n",
            "Epoch 7/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4184 - binary_accuracy: 0.8317\n",
            "Epoch 8/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.8111\n",
            "Epoch 9/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4287 - binary_accuracy: 0.8222\n",
            "Epoch 10/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4259 - binary_accuracy: 0.8317\n",
            "Epoch 11/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4154 - binary_accuracy: 0.8270\n",
            "Epoch 12/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4452 - binary_accuracy: 0.7952\n",
            "Epoch 13/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4144 - binary_accuracy: 0.8365\n",
            "Epoch 14/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3992 - binary_accuracy: 0.8349\n",
            "Epoch 15/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4392 - binary_accuracy: 0.8143\n",
            "Epoch 16/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4124 - binary_accuracy: 0.8254\n",
            "Epoch 17/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4234 - binary_accuracy: 0.8079\n",
            "Epoch 18/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4099 - binary_accuracy: 0.8302\n",
            "Epoch 19/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4080 - binary_accuracy: 0.8302\n",
            "Epoch 20/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4211 - binary_accuracy: 0.8302\n",
            "Epoch 21/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4308 - binary_accuracy: 0.8143\n",
            "Epoch 22/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3985 - binary_accuracy: 0.8460\n",
            "Epoch 23/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4013 - binary_accuracy: 0.8413\n",
            "Epoch 24/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4128 - binary_accuracy: 0.8317\n",
            "Epoch 25/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4185 - binary_accuracy: 0.8190\n",
            "Epoch 26/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3964 - binary_accuracy: 0.8444\n",
            "Epoch 27/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4111 - binary_accuracy: 0.8254\n",
            "Epoch 28/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4103 - binary_accuracy: 0.8270\n",
            "Epoch 29/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4101 - binary_accuracy: 0.8333\n",
            "Epoch 30/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4125 - binary_accuracy: 0.8317\n",
            "Epoch 31/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4485 - binary_accuracy: 0.8206\n",
            "Epoch 32/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4112 - binary_accuracy: 0.8222\n",
            "Epoch 33/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4182 - binary_accuracy: 0.8190\n",
            "Epoch 34/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4321 - binary_accuracy: 0.8175\n",
            "Epoch 35/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4112 - binary_accuracy: 0.8349\n",
            "Epoch 36/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4397 - binary_accuracy: 0.8143\n",
            "Epoch 37/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4410 - binary_accuracy: 0.8063\n",
            "Epoch 38/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4208 - binary_accuracy: 0.8254\n",
            "Epoch 39/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4208 - binary_accuracy: 0.8190\n",
            "Epoch 40/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3941 - binary_accuracy: 0.8476\n",
            "Epoch 41/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4101 - binary_accuracy: 0.8397\n",
            "Epoch 42/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4095 - binary_accuracy: 0.8333\n",
            "Epoch 43/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4147 - binary_accuracy: 0.8286\n",
            "Epoch 44/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4201 - binary_accuracy: 0.8381\n",
            "Epoch 45/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4147 - binary_accuracy: 0.8286\n",
            "Epoch 46/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4045 - binary_accuracy: 0.8508\n",
            "Epoch 47/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4185 - binary_accuracy: 0.8365\n",
            "Epoch 48/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4377 - binary_accuracy: 0.8143\n",
            "Epoch 49/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4259 - binary_accuracy: 0.8190\n",
            "Epoch 50/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4020 - binary_accuracy: 0.8333\n",
            "Epoch 51/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4196 - binary_accuracy: 0.8270\n",
            "Epoch 52/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4215 - binary_accuracy: 0.8111\n",
            "Epoch 53/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4347 - binary_accuracy: 0.8206\n",
            "Epoch 54/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4113 - binary_accuracy: 0.8429\n",
            "Epoch 55/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4320 - binary_accuracy: 0.8127\n",
            "Epoch 56/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4098 - binary_accuracy: 0.8429\n",
            "Epoch 57/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4100 - binary_accuracy: 0.8429\n",
            "Epoch 58/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4102 - binary_accuracy: 0.8397\n",
            "Epoch 59/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3986 - binary_accuracy: 0.8492\n",
            "Epoch 60/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4139 - binary_accuracy: 0.8397\n",
            "Epoch 61/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4270 - binary_accuracy: 0.8365\n",
            "Epoch 62/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3957 - binary_accuracy: 0.8476\n",
            "Epoch 63/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4225 - binary_accuracy: 0.8270\n",
            "Epoch 64/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4013 - binary_accuracy: 0.8413\n",
            "Epoch 65/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4216 - binary_accuracy: 0.8286\n",
            "Epoch 66/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4234 - binary_accuracy: 0.8381\n",
            "Epoch 67/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4094 - binary_accuracy: 0.8333\n",
            "Epoch 68/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4078 - binary_accuracy: 0.8444\n",
            "Epoch 69/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4083 - binary_accuracy: 0.8349\n",
            "Epoch 70/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4070 - binary_accuracy: 0.8476\n",
            "Epoch 71/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4334 - binary_accuracy: 0.8190\n",
            "Epoch 72/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4435 - binary_accuracy: 0.8111\n",
            "Epoch 73/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4291 - binary_accuracy: 0.8302\n",
            "Epoch 74/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4397 - binary_accuracy: 0.8333\n",
            "Epoch 75/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4235 - binary_accuracy: 0.8349\n",
            "Epoch 76/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4918 - binary_accuracy: 0.7984\n",
            "Epoch 77/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4141 - binary_accuracy: 0.8254\n",
            "Epoch 78/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4906 - binary_accuracy: 0.7968\n",
            "Epoch 79/190\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.4206 - binary_accuracy: 0.8190\n",
            "Epoch 80/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4396 - binary_accuracy: 0.8175\n",
            "Epoch 81/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4164 - binary_accuracy: 0.8429\n",
            "Epoch 82/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4393 - binary_accuracy: 0.8016\n",
            "Epoch 83/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4489 - binary_accuracy: 0.8222\n",
            "Epoch 84/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3970 - binary_accuracy: 0.8460\n",
            "Epoch 85/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4128 - binary_accuracy: 0.8365\n",
            "Epoch 86/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4072 - binary_accuracy: 0.8333\n",
            "Epoch 87/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4072 - binary_accuracy: 0.8524\n",
            "Epoch 88/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4041 - binary_accuracy: 0.8429\n",
            "Epoch 89/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4399 - binary_accuracy: 0.8206\n",
            "Epoch 90/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4027 - binary_accuracy: 0.8492\n",
            "Epoch 91/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4337 - binary_accuracy: 0.8143\n",
            "Epoch 92/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4474 - binary_accuracy: 0.8190\n",
            "Epoch 93/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4698 - binary_accuracy: 0.8016\n",
            "Epoch 94/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4419 - binary_accuracy: 0.8143\n",
            "Epoch 95/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4264 - binary_accuracy: 0.8190\n",
            "Epoch 96/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4439 - binary_accuracy: 0.7984\n",
            "Epoch 97/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4151 - binary_accuracy: 0.8444\n",
            "Epoch 98/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4300 - binary_accuracy: 0.8190\n",
            "Epoch 99/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4161 - binary_accuracy: 0.8302\n",
            "Epoch 100/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4200 - binary_accuracy: 0.8365\n",
            "Epoch 101/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4299 - binary_accuracy: 0.8111\n",
            "Epoch 102/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4256 - binary_accuracy: 0.8333\n",
            "Epoch 103/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4256 - binary_accuracy: 0.8222\n",
            "Epoch 104/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4135 - binary_accuracy: 0.8238\n",
            "Epoch 105/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4449 - binary_accuracy: 0.8048\n",
            "Epoch 106/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4108 - binary_accuracy: 0.8444\n",
            "Epoch 107/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4019 - binary_accuracy: 0.8397\n",
            "Epoch 108/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4234 - binary_accuracy: 0.8365\n",
            "Epoch 109/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4118 - binary_accuracy: 0.8270\n",
            "Epoch 110/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4496 - binary_accuracy: 0.8048\n",
            "Epoch 111/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4040 - binary_accuracy: 0.8270\n",
            "Epoch 112/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4212 - binary_accuracy: 0.8270\n",
            "Epoch 113/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4093 - binary_accuracy: 0.8460\n",
            "Epoch 114/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4478 - binary_accuracy: 0.8032\n",
            "Epoch 115/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4471 - binary_accuracy: 0.8190\n",
            "Epoch 116/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4253 - binary_accuracy: 0.8238\n",
            "Epoch 117/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4261 - binary_accuracy: 0.8302\n",
            "Epoch 118/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4350 - binary_accuracy: 0.8222\n",
            "Epoch 119/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4664 - binary_accuracy: 0.7794\n",
            "Epoch 120/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4348 - binary_accuracy: 0.8095\n",
            "Epoch 121/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4244 - binary_accuracy: 0.8365\n",
            "Epoch 122/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4186 - binary_accuracy: 0.8317\n",
            "Epoch 123/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4273 - binary_accuracy: 0.8206\n",
            "Epoch 124/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4370 - binary_accuracy: 0.8254\n",
            "Epoch 125/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4099 - binary_accuracy: 0.8333\n",
            "Epoch 126/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4002 - binary_accuracy: 0.8381\n",
            "Epoch 127/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4210 - binary_accuracy: 0.8381\n",
            "Epoch 128/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4170 - binary_accuracy: 0.8286\n",
            "Epoch 129/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4188 - binary_accuracy: 0.8254\n",
            "Epoch 130/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4295 - binary_accuracy: 0.8095\n",
            "Epoch 131/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4146 - binary_accuracy: 0.8397\n",
            "Epoch 132/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4199 - binary_accuracy: 0.8270\n",
            "Epoch 133/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - binary_accuracy: 0.7873\n",
            "Epoch 134/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4244 - binary_accuracy: 0.8159\n",
            "Epoch 135/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4176 - binary_accuracy: 0.8413\n",
            "Epoch 136/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4116 - binary_accuracy: 0.8254\n",
            "Epoch 137/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4119 - binary_accuracy: 0.8349\n",
            "Epoch 138/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4112 - binary_accuracy: 0.8460\n",
            "Epoch 139/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4426 - binary_accuracy: 0.8254\n",
            "Epoch 140/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4892 - binary_accuracy: 0.7952\n",
            "Epoch 141/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4678 - binary_accuracy: 0.8063\n",
            "Epoch 142/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4179 - binary_accuracy: 0.8397\n",
            "Epoch 143/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4367 - binary_accuracy: 0.8317\n",
            "Epoch 144/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4232 - binary_accuracy: 0.8238\n",
            "Epoch 145/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4746 - binary_accuracy: 0.8238\n",
            "Epoch 146/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4456 - binary_accuracy: 0.8175\n",
            "Epoch 147/190\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.4313 - binary_accuracy: 0.8317\n",
            "Epoch 148/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8063\n",
            "Epoch 149/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4303 - binary_accuracy: 0.8460\n",
            "Epoch 150/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4123 - binary_accuracy: 0.8381\n",
            "Epoch 151/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4786 - binary_accuracy: 0.7984\n",
            "Epoch 152/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4395 - binary_accuracy: 0.8254\n",
            "Epoch 153/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4153 - binary_accuracy: 0.8381\n",
            "Epoch 154/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4256 - binary_accuracy: 0.8190\n",
            "Epoch 155/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4753 - binary_accuracy: 0.7984\n",
            "Epoch 156/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4016 - binary_accuracy: 0.8429\n",
            "Epoch 157/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4213 - binary_accuracy: 0.8159\n",
            "Epoch 158/190\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4046 - binary_accuracy: 0.8381\n",
            "Epoch 159/190\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.4356 - binary_accuracy: 0.8254\n",
            "Epoch 160/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4223 - binary_accuracy: 0.8286\n",
            "Epoch 161/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4172 - binary_accuracy: 0.8270\n",
            "Epoch 162/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4297 - binary_accuracy: 0.8286\n",
            "Epoch 163/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4204 - binary_accuracy: 0.8508\n",
            "Epoch 164/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4280 - binary_accuracy: 0.8302\n",
            "Epoch 165/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4488 - binary_accuracy: 0.8159\n",
            "Epoch 166/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4050 - binary_accuracy: 0.8492\n",
            "Epoch 167/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4319 - binary_accuracy: 0.8317\n",
            "Epoch 168/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4036 - binary_accuracy: 0.8444\n",
            "Epoch 169/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4354 - binary_accuracy: 0.8317\n",
            "Epoch 170/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4132 - binary_accuracy: 0.8365\n",
            "Epoch 171/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4435 - binary_accuracy: 0.8143\n",
            "Epoch 172/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4511 - binary_accuracy: 0.8175\n",
            "Epoch 173/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4058 - binary_accuracy: 0.8540\n",
            "Epoch 174/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4148 - binary_accuracy: 0.8286\n",
            "Epoch 175/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4171 - binary_accuracy: 0.8349\n",
            "Epoch 176/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4055 - binary_accuracy: 0.8460\n",
            "Epoch 177/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4409 - binary_accuracy: 0.8222\n",
            "Epoch 178/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4264 - binary_accuracy: 0.8317\n",
            "Epoch 179/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4468 - binary_accuracy: 0.8016\n",
            "Epoch 180/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - binary_accuracy: 0.8079\n",
            "Epoch 181/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4126 - binary_accuracy: 0.8460\n",
            "Epoch 182/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4356 - binary_accuracy: 0.8238\n",
            "Epoch 183/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4352 - binary_accuracy: 0.8159\n",
            "Epoch 184/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4224 - binary_accuracy: 0.8349\n",
            "Epoch 185/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4251 - binary_accuracy: 0.8238\n",
            "Epoch 186/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - binary_accuracy: 0.7921\n",
            "Epoch 187/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4300 - binary_accuracy: 0.8238\n",
            "Epoch 188/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4275 - binary_accuracy: 0.8254\n",
            "Epoch 189/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4422 - binary_accuracy: 0.8222\n",
            "Epoch 190/190\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4303 - binary_accuracy: 0.8143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f3597a486a0>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# executando a Rede Neural com a Base de Dados\n",
        "previsoes = classificador.predict(previsores_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7O99K-80_VA",
        "outputId": "9788fa60-0f72-4d94-8a6b-e103c7c4e60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgdUQUZd1DC_",
        "outputId": "4953e005-ee37-4110-d2a2-b407c81108d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7698403 ],\n",
              "       [0.9549105 ],\n",
              "       [0.3292462 ],\n",
              "       [0.54809374],\n",
              "       [0.05574378],\n",
              "       [0.03490391],\n",
              "       [0.76904744],\n",
              "       [0.31372964],\n",
              "       [0.1500929 ],\n",
              "       [0.7639432 ],\n",
              "       [0.28489435],\n",
              "       [0.28702283],\n",
              "       [0.15527995],\n",
              "       [0.77528036],\n",
              "       [0.29623255],\n",
              "       [0.08367134],\n",
              "       [0.17141461],\n",
              "       [0.13675371],\n",
              "       [0.30066034],\n",
              "       [0.20163245],\n",
              "       [0.9246989 ],\n",
              "       [0.97123474],\n",
              "       [0.7398855 ],\n",
              "       [0.06032872],\n",
              "       [0.13481408],\n",
              "       [0.24691345],\n",
              "       [0.05907571],\n",
              "       [0.9827342 ],\n",
              "       [0.92382395],\n",
              "       [0.21274167],\n",
              "       [0.20553549],\n",
              "       [0.1764898 ],\n",
              "       [0.04768891],\n",
              "       [0.99151844],\n",
              "       [0.99851406],\n",
              "       [0.10414848],\n",
              "       [0.5927533 ],\n",
              "       [0.10901113],\n",
              "       [0.33438927],\n",
              "       [0.8640167 ],\n",
              "       [0.98242265],\n",
              "       [0.05153272],\n",
              "       [0.35773227],\n",
              "       [0.9454125 ],\n",
              "       [0.1857343 ],\n",
              "       [0.08167434],\n",
              "       [0.9326079 ],\n",
              "       [0.9466918 ],\n",
              "       [0.6245087 ],\n",
              "       [0.8072125 ],\n",
              "       [0.21448034],\n",
              "       [0.059787  ],\n",
              "       [0.11699947],\n",
              "       [0.9874383 ],\n",
              "       [0.8180825 ],\n",
              "       [0.04940671],\n",
              "       [0.99328876],\n",
              "       [0.36558777],\n",
              "       [0.5192579 ],\n",
              "       [0.9406327 ],\n",
              "       [0.09401046],\n",
              "       [0.5840224 ],\n",
              "       [0.7925535 ],\n",
              "       [0.5083797 ],\n",
              "       [0.8852404 ],\n",
              "       [0.9952158 ],\n",
              "       [0.99952143],\n",
              "       [0.11093386],\n",
              "       [0.15326047],\n",
              "       [0.14150652],\n",
              "       [0.09058956],\n",
              "       [0.85400724],\n",
              "       [0.99922967],\n",
              "       [0.8946974 ],\n",
              "       [0.13310501],\n",
              "       [0.2816337 ],\n",
              "       [0.2528785 ],\n",
              "       [0.03437908],\n",
              "       [0.09266889],\n",
              "       [0.9735027 ],\n",
              "       [0.82899755],\n",
              "       [0.16776527],\n",
              "       [0.79436535],\n",
              "       [0.09878501],\n",
              "       [0.4126962 ],\n",
              "       [0.97962296],\n",
              "       [0.04547251],\n",
              "       [0.08312565],\n",
              "       [0.20898898],\n",
              "       [0.19218053],\n",
              "       [0.5803666 ],\n",
              "       [0.99513364],\n",
              "       [0.8574894 ],\n",
              "       [0.66653794],\n",
              "       [0.08981109],\n",
              "       [0.5121636 ],\n",
              "       [0.17911352],\n",
              "       [0.999392  ],\n",
              "       [0.84990126],\n",
              "       [0.99773437],\n",
              "       [0.7569362 ],\n",
              "       [1.        ],\n",
              "       [0.07372189],\n",
              "       [0.8423117 ],\n",
              "       [0.12965532],\n",
              "       [0.06324603],\n",
              "       [0.10353251],\n",
              "       [0.5185545 ],\n",
              "       [0.52719307],\n",
              "       [0.9158074 ],\n",
              "       [0.07357726],\n",
              "       [0.63249516],\n",
              "       [0.95335764],\n",
              "       [0.84673077],\n",
              "       [0.09390671],\n",
              "       [0.23486   ],\n",
              "       [0.9938065 ],\n",
              "       [0.7983151 ],\n",
              "       [0.9968154 ],\n",
              "       [0.53771734],\n",
              "       [0.2781338 ],\n",
              "       [0.06015202],\n",
              "       [0.18706977],\n",
              "       [0.978707  ],\n",
              "       [0.4359929 ],\n",
              "       [0.7291941 ],\n",
              "       [0.92773575],\n",
              "       [0.03457787],\n",
              "       [0.76370263],\n",
              "       [0.09537933],\n",
              "       [0.9732224 ],\n",
              "       [0.9917507 ],\n",
              "       [0.03786722],\n",
              "       [0.19390658],\n",
              "       [0.28480306],\n",
              "       [0.07288565],\n",
              "       [0.9733283 ],\n",
              "       [0.57076925],\n",
              "       [0.760399  ],\n",
              "       [0.974496  ],\n",
              "       [0.15022297],\n",
              "       [0.9002388 ],\n",
              "       [0.18139271],\n",
              "       [0.5945546 ],\n",
              "       [0.9832073 ],\n",
              "       [0.03512935],\n",
              "       [0.960339  ],\n",
              "       [0.36668935],\n",
              "       [0.12214419],\n",
              "       [0.45466042],\n",
              "       [0.07325947],\n",
              "       [0.07141786],\n",
              "       [0.9944838 ],\n",
              "       [0.947276  ],\n",
              "       [0.62106615],\n",
              "       [0.2941009 ],\n",
              "       [0.1725755 ],\n",
              "       [0.04559943],\n",
              "       [0.03428646],\n",
              "       [0.16706617],\n",
              "       [0.9931342 ],\n",
              "       [0.06739962],\n",
              "       [0.14749974],\n",
              "       [0.25738752],\n",
              "       [0.12043913],\n",
              "       [0.12942252],\n",
              "       [0.04552583],\n",
              "       [0.14133146],\n",
              "       [0.6548909 ],\n",
              "       [0.2294714 ],\n",
              "       [0.80910736],\n",
              "       [0.04848727],\n",
              "       [0.8359642 ],\n",
              "       [0.10291487],\n",
              "       [0.11545069],\n",
              "       [0.9244207 ],\n",
              "       [0.8461659 ],\n",
              "       [0.18071337],\n",
              "       [0.03501474],\n",
              "       [0.9920465 ],\n",
              "       [0.14619865],\n",
              "       [0.9402336 ],\n",
              "       [0.6652682 ],\n",
              "       [0.34626544],\n",
              "       [0.97462934],\n",
              "       [0.9980525 ],\n",
              "       [0.2164772 ],\n",
              "       [0.6303631 ],\n",
              "       [0.9957128 ],\n",
              "       [0.34823138],\n",
              "       [0.8516372 ],\n",
              "       [0.34122753],\n",
              "       [0.97697014],\n",
              "       [0.1870614 ],\n",
              "       [0.07363466],\n",
              "       [0.09543839],\n",
              "       [0.0930047 ],\n",
              "       [0.9982386 ],\n",
              "       [0.95902246],\n",
              "       [0.07356732],\n",
              "       [0.24904883],\n",
              "       [0.21562855],\n",
              "       [0.15622711],\n",
              "       [0.14626868],\n",
              "       [0.99637896],\n",
              "       [0.09658232],\n",
              "       [0.0855584 ],\n",
              "       [0.39077035],\n",
              "       [0.15668924],\n",
              "       [0.04403385],\n",
              "       [0.9831965 ],\n",
              "       [0.85584176],\n",
              "       [0.13850735],\n",
              "       [0.5360517 ],\n",
              "       [0.66240364],\n",
              "       [0.6994968 ],\n",
              "       [0.9913758 ],\n",
              "       [0.07098133],\n",
              "       [0.48074815],\n",
              "       [0.13870834],\n",
              "       [0.33608812],\n",
              "       [0.11696647],\n",
              "       [0.24010491],\n",
              "       [0.93030673],\n",
              "       [0.98708445],\n",
              "       [0.8433743 ],\n",
              "       [0.1168537 ],\n",
              "       [0.24219035],\n",
              "       [0.60347474],\n",
              "       [0.6945833 ],\n",
              "       [0.92729974],\n",
              "       [0.12649788],\n",
              "       [0.50849724],\n",
              "       [0.16852474],\n",
              "       [0.13298711],\n",
              "       [0.13536899],\n",
              "       [0.7320992 ],\n",
              "       [0.99578536],\n",
              "       [0.9307493 ],\n",
              "       [0.10171083],\n",
              "       [0.77517   ],\n",
              "       [0.06435338],\n",
              "       [0.1604232 ],\n",
              "       [0.07901096],\n",
              "       [0.17907691],\n",
              "       [0.08417086],\n",
              "       [0.75171226],\n",
              "       [0.28300104],\n",
              "       [0.8330894 ],\n",
              "       [0.26824573],\n",
              "       [0.33568898],\n",
              "       [0.13714   ],\n",
              "       [0.8528544 ],\n",
              "       [0.18407963],\n",
              "       [0.11267908],\n",
              "       [0.69212   ],\n",
              "       [0.18742198],\n",
              "       [0.6951012 ],\n",
              "       [0.11347174],\n",
              "       [0.36939806],\n",
              "       [0.1675059 ],\n",
              "       [0.9999661 ],\n",
              "       [0.3713746 ],\n",
              "       [0.97210485],\n",
              "       [0.9367306 ],\n",
              "       [0.7193416 ],\n",
              "       [0.9840153 ],\n",
              "       [0.10350733],\n",
              "       [0.9064931 ],\n",
              "       [0.16062573]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convertendo as previsoes da Rede Neural para V ou F\n",
        "previsoes = (previsoes > 0.5)\n",
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOKDUF_e1EgX",
        "outputId": "473953ab-6d3a-4517-f09f-f67b1514bd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# avaliando o acerto - comparar previsoes e classe_teste\n",
        "#importando o método de comparação\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#avaliando a precisão das previsoes com a classe teste\n",
        "precisao = accuracy_score(classe_teste, previsoes)"
      ],
      "metadata": {
        "id": "etJ5DuvT1Gvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mostrando a precisao\n",
        "precisao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfEK9dcD1I6_",
        "outputId": "e0ce54e7-b376-421d-d618-f621bfcfe1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9037037037037037"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliandoi o acerto - comparar previsores e classe_teste\n",
        "#usando recursos do Keras\n",
        "resultado= classificador.evaluate(previsores_teste, classe_teste)\n",
        "resultado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKHZt17H1K6_",
        "outputId": "212432f2-f74a-4d8c-92d8-49290b579ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2816 - binary_accuracy: 0.9037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2815520167350769, 0.9037036895751953]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = classificador.evaluate(previsores_teste, classe_teste)\n",
        "print('Loss: %.2f' % loss)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx8D64nOOCEz",
        "outputId": "60f9520f-0667-44ad-cc81-a33276044eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2816 - binary_accuracy: 0.9037\n",
            "Loss: 0.28\n",
            "Accuracy: 90.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Percentual de acerto final de 90.37%\n",
        "\n",
        "##Parametros utilizados:\n",
        "####•3 camadas ocultas com ativação reLu com 32, 32 e 16 neuronios e 1 camada de saída com ativação sigmoid\n",
        "####•Otimizador adam com weight_decay = 0.0021 e clipvalue = 5.5\n",
        "####•Batch size de 8 e 190 epocas\n"
      ],
      "metadata": {
        "id": "POKndRVwImzJ"
      }
    }
  ]
}