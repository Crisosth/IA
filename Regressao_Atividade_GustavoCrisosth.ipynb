{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNezBUGhutxHheoW60DWo/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Crisosth/IA/blob/main/Regressao_Atividade_GustavoCrisosth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sqE1Spuhl_5G",
        "outputId": "12504993-6dc8-4f71-8e47-493f571d6ba4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   case  site  Pop sex  age  hdlngth  skullw  totlngth  taill  footlgth  \\\n",
              "0     1     1  Vic   m  8.0     94.1    60.4      89.0   36.0      74.5   \n",
              "1     2     1  Vic   f  6.0     92.5    57.6      91.5   36.5      72.5   \n",
              "2     3     1  Vic   f  6.0     94.0    60.0      95.5   39.0      75.4   \n",
              "3     4     1  Vic   f  6.0     93.2    57.1      92.0   38.0      76.1   \n",
              "4     5     1  Vic   f  2.0     91.5    56.3      85.5   36.0      71.0   \n",
              "\n",
              "   earconch   eye  chest  belly  \n",
              "0      54.5  15.2   28.0   36.0  \n",
              "1      51.2  16.0   28.5   33.0  \n",
              "2      51.9  15.5   30.0   34.0  \n",
              "3      52.2  15.2   28.0   34.0  \n",
              "4      53.2  15.1   28.5   33.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-384a15a2-a7d9-4ffe-bf6a-f391363e077d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case</th>\n",
              "      <th>site</th>\n",
              "      <th>Pop</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>hdlngth</th>\n",
              "      <th>skullw</th>\n",
              "      <th>totlngth</th>\n",
              "      <th>taill</th>\n",
              "      <th>footlgth</th>\n",
              "      <th>earconch</th>\n",
              "      <th>eye</th>\n",
              "      <th>chest</th>\n",
              "      <th>belly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Vic</td>\n",
              "      <td>m</td>\n",
              "      <td>8.0</td>\n",
              "      <td>94.1</td>\n",
              "      <td>60.4</td>\n",
              "      <td>89.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>74.5</td>\n",
              "      <td>54.5</td>\n",
              "      <td>15.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Vic</td>\n",
              "      <td>f</td>\n",
              "      <td>6.0</td>\n",
              "      <td>92.5</td>\n",
              "      <td>57.6</td>\n",
              "      <td>91.5</td>\n",
              "      <td>36.5</td>\n",
              "      <td>72.5</td>\n",
              "      <td>51.2</td>\n",
              "      <td>16.0</td>\n",
              "      <td>28.5</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Vic</td>\n",
              "      <td>f</td>\n",
              "      <td>6.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>95.5</td>\n",
              "      <td>39.0</td>\n",
              "      <td>75.4</td>\n",
              "      <td>51.9</td>\n",
              "      <td>15.5</td>\n",
              "      <td>30.0</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Vic</td>\n",
              "      <td>f</td>\n",
              "      <td>6.0</td>\n",
              "      <td>93.2</td>\n",
              "      <td>57.1</td>\n",
              "      <td>92.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.1</td>\n",
              "      <td>52.2</td>\n",
              "      <td>15.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Vic</td>\n",
              "      <td>f</td>\n",
              "      <td>2.0</td>\n",
              "      <td>91.5</td>\n",
              "      <td>56.3</td>\n",
              "      <td>85.5</td>\n",
              "      <td>36.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>53.2</td>\n",
              "      <td>15.1</td>\n",
              "      <td>28.5</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-384a15a2-a7d9-4ffe-bf6a-f391363e077d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-384a15a2-a7d9-4ffe-bf6a-f391363e077d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-384a15a2-a7d9-4ffe-bf6a-f391363e077d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3bd37a61-da62-4c08-8929-8ca734b58a9d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3bd37a61-da62-4c08-8929-8ca734b58a9d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3bd37a61-da62-4c08-8929-8ca734b58a9d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "base",
              "summary": "{\n  \"name\": \"base\",\n  \"rows\": 104,\n  \"fields\": [\n    {\n      \"column\": \"case\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 1,\n        \"max\": 104,\n        \"num_unique_values\": 104,\n        \"samples\": [\n          31,\n          66,\n          65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"site\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pop\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"other\",\n          \"Vic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"f\",\n          \"m\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9092444897006104,\n        \"min\": 1.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          4.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hdlngth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.573349486079402,\n        \"min\": 82.5,\n        \"max\": 103.1,\n        \"num_unique_values\": 71,\n        \"samples\": [\n          96.0,\n          94.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skullw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1134256903770203,\n        \"min\": 50.0,\n        \"max\": 68.6,\n        \"num_unique_values\": 64,\n        \"samples\": [\n          50.0,\n          58.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"totlngth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.310549436569344,\n        \"min\": 75.0,\n        \"max\": 96.5,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          93.0,\n          75.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"taill\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.959518428592603,\n        \"min\": 32.0,\n        \"max\": 43.0,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          36.0,\n          37.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"footlgth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.395305804641412,\n        \"min\": 60.3,\n        \"max\": 77.9,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          71.0,\n          60.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"earconch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.109380151285827,\n        \"min\": 40.3,\n        \"max\": 56.2,\n        \"num_unique_values\": 69,\n        \"samples\": [\n          56.2,\n          54.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eye\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0503742353818448,\n        \"min\": 12.8,\n        \"max\": 17.8,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          16.5,\n          15.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0455967391979963,\n        \"min\": 22.0,\n        \"max\": 32.0,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          28.0,\n          31.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"belly\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7619487172923667,\n        \"min\": 25.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          40.0,\n          27.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#importando as bibliotecas\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "##carregando a base de dados\n",
        "base = pd.read_csv(\"gamba.csv\", encoding = 'ISO-8859-1')\n",
        "base.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deletando as colunas não importantes\n",
        "# axis = 1 - deletar a coluna inteira\n",
        "base = base.drop('case', axis=1)\n",
        "base = base.drop('earconch', axis=1)\n",
        "base = base.drop('eye', axis=1)\n",
        "base = base.drop('chest', axis=1)\n",
        "base = base.drop('belly', axis=1)"
      ],
      "metadata": {
        "id": "CW95r2Z_ndQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or0BDrBcoVG9",
        "outputId": "a4b00d79-47bd-4a0c-e3a8-0f49b4011735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "site        0\n",
              "Pop         0\n",
              "sex         0\n",
              "age         2\n",
              "hdlngth     0\n",
              "skullw      0\n",
              "totlngth    0\n",
              "taill       0\n",
              "footlgth    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preenchendo os valores faltantes com a mediana\n",
        "base['age'].fillna(base['age'].median(), inplace=True)\n",
        "base['footlgth'].fillna(base['footlgth'].median(), inplace=True)"
      ],
      "metadata": {
        "id": "izpVm8HhopBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjSer8GXospD",
        "outputId": "98015685-2513-4ea5-ee2f-e82eb169b668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "site        0\n",
              "Pop         0\n",
              "sex         0\n",
              "age         0\n",
              "hdlngth     0\n",
              "skullw      0\n",
              "totlngth    0\n",
              "taill       0\n",
              "footlgth    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = base[['site', 'Pop', 'sex', 'hdlngth', 'skullw', 'totlngth', 'taill', 'footlgth']].values\n",
        "previsores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixnZMhmipGdC",
        "outputId": "7324580d-a1cb-4571-a9ce-616220879ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 'Vic', 'm', 94.1, 60.4, 89.0, 36.0, 74.5],\n",
              "       [1, 'Vic', 'f', 92.5, 57.6, 91.5, 36.5, 72.5],\n",
              "       [1, 'Vic', 'f', 94.0, 60.0, 95.5, 39.0, 75.4],\n",
              "       [1, 'Vic', 'f', 93.2, 57.1, 92.0, 38.0, 76.1],\n",
              "       [1, 'Vic', 'f', 91.5, 56.3, 85.5, 36.0, 71.0],\n",
              "       [1, 'Vic', 'f', 93.1, 54.8, 90.5, 35.5, 73.2],\n",
              "       [1, 'Vic', 'm', 95.3, 58.2, 89.5, 36.0, 71.5],\n",
              "       [1, 'Vic', 'f', 94.8, 57.6, 91.0, 37.0, 72.7],\n",
              "       [1, 'Vic', 'f', 93.4, 56.3, 91.5, 37.0, 72.4],\n",
              "       [1, 'Vic', 'f', 91.8, 58.0, 89.5, 37.5, 70.9],\n",
              "       [1, 'Vic', 'f', 93.3, 57.2, 89.5, 39.0, 77.2],\n",
              "       [1, 'Vic', 'f', 94.9, 55.6, 92.0, 35.5, 71.7],\n",
              "       [1, 'Vic', 'm', 95.1, 59.9, 89.5, 36.0, 71.0],\n",
              "       [1, 'Vic', 'm', 95.4, 57.6, 91.5, 36.0, 74.3],\n",
              "       [1, 'Vic', 'm', 92.9, 57.6, 85.5, 34.0, 69.7],\n",
              "       [1, 'Vic', 'm', 91.6, 56.0, 86.0, 34.5, 73.0],\n",
              "       [1, 'Vic', 'f', 94.7, 67.7, 89.5, 36.5, 73.2],\n",
              "       [1, 'Vic', 'm', 93.5, 55.7, 90.0, 36.0, 73.7],\n",
              "       [1, 'Vic', 'f', 94.4, 55.4, 90.5, 35.0, 73.4],\n",
              "       [1, 'Vic', 'f', 94.8, 56.3, 89.0, 38.0, 73.8],\n",
              "       [1, 'Vic', 'f', 95.9, 58.1, 96.5, 39.5, 77.9],\n",
              "       [1, 'Vic', 'm', 96.3, 58.5, 91.0, 39.5, 73.5],\n",
              "       [1, 'Vic', 'f', 92.5, 56.1, 89.0, 36.0, 72.8],\n",
              "       [1, 'Vic', 'm', 94.4, 54.9, 84.0, 34.0, 75.0],\n",
              "       [1, 'Vic', 'm', 95.8, 58.5, 91.5, 35.5, 72.3],\n",
              "       [1, 'Vic', 'm', 96.0, 59.0, 90.0, 36.0, 73.6],\n",
              "       [1, 'Vic', 'f', 90.5, 54.5, 85.0, 35.0, 70.3],\n",
              "       [1, 'Vic', 'm', 93.8, 56.8, 87.0, 34.5, 73.2],\n",
              "       [1, 'Vic', 'f', 92.8, 56.0, 88.0, 35.0, 74.9],\n",
              "       [1, 'Vic', 'f', 92.1, 54.4, 84.0, 33.5, 70.6],\n",
              "       [1, 'Vic', 'm', 92.8, 54.1, 93.0, 37.0, 68.0],\n",
              "       [1, 'Vic', 'f', 94.3, 56.7, 94.0, 39.0, 74.8],\n",
              "       [1, 'Vic', 'm', 91.4, 54.6, 89.0, 37.0, 70.8],\n",
              "       [2, 'Vic', 'm', 90.6, 55.7, 85.5, 36.5, 73.1],\n",
              "       [2, 'Vic', 'm', 94.4, 57.9, 85.0, 35.5, 71.2],\n",
              "       [2, 'Vic', 'm', 93.3, 59.3, 88.0, 35.0, 74.3],\n",
              "       [2, 'Vic', 'f', 89.3, 54.8, 82.5, 35.0, 71.2],\n",
              "       [2, 'Vic', 'm', 92.4, 56.0, 80.5, 35.5, 68.4],\n",
              "       [2, 'Vic', 'f', 84.7, 51.5, 75.0, 34.0, 68.7],\n",
              "       [2, 'Vic', 'f', 91.0, 55.0, 84.5, 36.0, 72.8],\n",
              "       [2, 'Vic', 'f', 88.4, 57.0, 83.0, 36.5, 68.0],\n",
              "       [2, 'Vic', 'm', 85.3, 54.1, 77.0, 32.0, 62.7],\n",
              "       [2, 'Vic', 'f', 90.0, 55.5, 81.0, 32.0, 72.0],\n",
              "       [2, 'Vic', 'm', 85.1, 51.5, 76.0, 35.5, 70.3],\n",
              "       [2, 'Vic', 'm', 90.7, 55.9, 81.0, 34.0, 71.5],\n",
              "       [2, 'Vic', 'm', 91.4, 54.4, 84.0, 35.0, 72.8],\n",
              "       [3, 'other', 'm', 90.1, 54.8, 89.0, 37.5, 66.0],\n",
              "       [3, 'other', 'm', 98.6, 63.2, 85.0, 34.0, 66.9],\n",
              "       [3, 'other', 'm', 95.4, 59.2, 85.0, 37.0, 69.0],\n",
              "       [3, 'other', 'f', 91.6, 56.4, 88.0, 38.0, 65.0],\n",
              "       [3, 'other', 'f', 95.6, 59.6, 85.0, 36.0, 64.0],\n",
              "       [3, 'other', 'm', 97.6, 61.0, 93.5, 40.0, 67.9],\n",
              "       [3, 'other', 'f', 93.1, 58.1, 91.0, 38.0, 67.4],\n",
              "       [4, 'other', 'm', 96.9, 63.0, 91.5, 43.0, 71.3],\n",
              "       [4, 'other', 'm', 103.1, 63.2, 92.5, 38.0, 72.5],\n",
              "       [4, 'other', 'm', 99.9, 61.5, 93.7, 38.0, 68.7],\n",
              "       [4, 'other', 'f', 95.1, 59.4, 93.0, 41.0, 67.2],\n",
              "       [4, 'other', 'm', 94.5, 64.2, 91.0, 39.0, 66.5],\n",
              "       [4, 'other', 'm', 102.5, 62.8, 96.0, 40.0, 73.2],\n",
              "       [4, 'other', 'f', 91.3, 57.7, 88.0, 39.0, 63.1],\n",
              "       [5, 'other', 'm', 95.7, 59.0, 86.0, 38.0, 63.1],\n",
              "       [5, 'other', 'f', 91.3, 58.0, 90.5, 39.0, 65.5],\n",
              "       [5, 'other', 'f', 92.0, 56.4, 88.5, 38.0, 64.1],\n",
              "       [5, 'other', 'f', 96.9, 56.5, 89.5, 38.5, 63.0],\n",
              "       [5, 'other', 'f', 93.5, 57.4, 88.5, 38.0, 68.2],\n",
              "       [5, 'other', 'f', 90.4, 55.8, 86.0, 36.5, 63.2],\n",
              "       [5, 'other', 'm', 93.3, 57.6, 85.0, 36.5, 64.7],\n",
              "       [5, 'other', 'm', 94.1, 56.0, 88.5, 38.0, 65.9],\n",
              "       [5, 'other', 'm', 98.0, 55.6, 88.0, 37.5, 65.0],\n",
              "       [5, 'other', 'f', 91.9, 56.4, 87.0, 38.0, 65.4],\n",
              "       [5, 'other', 'm', 92.8, 57.6, 90.0, 40.0, 65.7],\n",
              "       [5, 'other', 'm', 85.9, 52.4, 80.5, 35.0, 62.0],\n",
              "       [5, 'other', 'm', 82.5, 52.3, 82.0, 36.5, 65.7],\n",
              "       [6, 'other', 'f', 88.7, 52.0, 83.0, 38.0, 61.5],\n",
              "       [6, 'other', 'm', 93.8, 58.1, 89.0, 38.0, 66.2],\n",
              "       [6, 'other', 'm', 92.4, 56.8, 89.0, 41.0, 64.5],\n",
              "       [6, 'other', 'm', 93.6, 56.2, 84.0, 36.0, 62.8],\n",
              "       [6, 'other', 'm', 86.5, 51.0, 81.0, 36.5, 63.0],\n",
              "       [6, 'other', 'm', 85.8, 50.0, 81.0, 36.5, 62.8],\n",
              "       [6, 'other', 'm', 86.7, 52.6, 84.0, 38.0, 62.3],\n",
              "       [6, 'other', 'm', 90.6, 56.0, 85.5, 38.0, 65.6],\n",
              "       [6, 'other', 'f', 86.0, 54.0, 82.0, 36.5, 60.7],\n",
              "       [6, 'other', 'f', 90.0, 53.8, 81.5, 36.0, 62.0],\n",
              "       [6, 'other', 'm', 88.4, 54.6, 80.5, 36.0, 62.6],\n",
              "       [6, 'other', 'm', 89.5, 56.2, 92.0, 40.5, 65.6],\n",
              "       [6, 'other', 'f', 88.2, 53.2, 86.5, 38.5, 60.3],\n",
              "       [7, 'other', 'm', 98.5, 60.7, 93.0, 41.5, 71.7],\n",
              "       [7, 'other', 'f', 89.6, 58.0, 87.5, 38.0, 66.7],\n",
              "       [7, 'other', 'm', 97.7, 58.4, 84.5, 35.0, 64.4],\n",
              "       [7, 'other', 'm', 92.6, 54.6, 85.0, 38.5, 69.8],\n",
              "       [7, 'other', 'm', 97.8, 59.6, 89.0, 38.0, 65.5],\n",
              "       [7, 'other', 'm', 90.7, 56.3, 85.0, 37.0, 67.6],\n",
              "       [7, 'other', 'm', 89.2, 54.0, 82.0, 38.0, 63.8],\n",
              "       [7, 'other', 'm', 91.8, 57.6, 84.0, 35.5, 64.2],\n",
              "       [7, 'other', 'm', 91.6, 56.6, 88.5, 37.5, 64.5],\n",
              "       [7, 'other', 'm', 94.8, 55.7, 83.0, 38.0, 66.5],\n",
              "       [7, 'other', 'm', 91.0, 53.1, 86.0, 38.0, 63.8],\n",
              "       [7, 'other', 'm', 93.2, 68.6, 84.0, 35.0, 65.6],\n",
              "       [7, 'other', 'f', 93.3, 56.2, 86.5, 38.5, 64.8],\n",
              "       [7, 'other', 'm', 89.5, 56.0, 81.5, 36.5, 66.0],\n",
              "       [7, 'other', 'm', 88.6, 54.7, 82.5, 39.0, 64.4],\n",
              "       [7, 'other', 'f', 92.4, 55.0, 89.0, 38.0, 63.5],\n",
              "       [7, 'other', 'm', 91.5, 55.2, 82.5, 36.5, 62.9],\n",
              "       [7, 'other', 'f', 93.6, 59.9, 89.0, 40.0, 67.6]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idade = base['age'].values"
      ],
      "metadata": {
        "id": "2vJqozDBp4aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDr4cUG9qwVc",
        "outputId": "49e5751b-e1e3-4f60-a02f-80f059f84ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8., 6., 6., 6., 2., 1., 2., 6., 9., 6., 9., 5., 5., 3., 5., 4., 1.,\n",
              "       2., 5., 4., 3., 3., 4., 2., 3., 7., 2., 4., 3., 2., 3., 4., 3., 2.,\n",
              "       4., 7., 2., 7., 1., 3., 5., 3., 2., 3., 3., 3., 2., 5., 4., 5., 5.,\n",
              "       6., 3., 7., 2., 3., 4., 3., 2., 2., 7., 3., 6., 3., 5., 3., 4., 5.,\n",
              "       5., 7., 6., 1., 1., 4., 6., 5., 6., 1., 1., 1., 3., 4., 3., 3., 3.,\n",
              "       3., 2., 2., 6., 3., 3., 2., 3., 7., 4., 4., 3., 5., 3., 1., 1., 6.,\n",
              "       4., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#criando o objeto da classe Label Encoder\n",
        "labelencoder_previsores = LabelEncoder ()"
      ],
      "metadata": {
        "id": "K9P4Tmm9rZAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores[:,1] = labelencoder_previsores.fit_transform(previsores[:,1])\n",
        "previsores[:,2] = labelencoder_previsores.fit_transform(previsores[:,2])"
      ],
      "metadata": {
        "id": "aq7hcrg3rcvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcbmgdXpsIld",
        "outputId": "ba8f1282-4f34-4bd0-cd24-467b0abcc903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 94.1, 60.4, 89.0, 36.0, 74.5],\n",
              "       [1, 0, 0, 92.5, 57.6, 91.5, 36.5, 72.5],\n",
              "       [1, 0, 0, 94.0, 60.0, 95.5, 39.0, 75.4],\n",
              "       [1, 0, 0, 93.2, 57.1, 92.0, 38.0, 76.1],\n",
              "       [1, 0, 0, 91.5, 56.3, 85.5, 36.0, 71.0],\n",
              "       [1, 0, 0, 93.1, 54.8, 90.5, 35.5, 73.2],\n",
              "       [1, 0, 1, 95.3, 58.2, 89.5, 36.0, 71.5],\n",
              "       [1, 0, 0, 94.8, 57.6, 91.0, 37.0, 72.7],\n",
              "       [1, 0, 0, 93.4, 56.3, 91.5, 37.0, 72.4],\n",
              "       [1, 0, 0, 91.8, 58.0, 89.5, 37.5, 70.9],\n",
              "       [1, 0, 0, 93.3, 57.2, 89.5, 39.0, 77.2],\n",
              "       [1, 0, 0, 94.9, 55.6, 92.0, 35.5, 71.7],\n",
              "       [1, 0, 1, 95.1, 59.9, 89.5, 36.0, 71.0],\n",
              "       [1, 0, 1, 95.4, 57.6, 91.5, 36.0, 74.3],\n",
              "       [1, 0, 1, 92.9, 57.6, 85.5, 34.0, 69.7],\n",
              "       [1, 0, 1, 91.6, 56.0, 86.0, 34.5, 73.0],\n",
              "       [1, 0, 0, 94.7, 67.7, 89.5, 36.5, 73.2],\n",
              "       [1, 0, 1, 93.5, 55.7, 90.0, 36.0, 73.7],\n",
              "       [1, 0, 0, 94.4, 55.4, 90.5, 35.0, 73.4],\n",
              "       [1, 0, 0, 94.8, 56.3, 89.0, 38.0, 73.8],\n",
              "       [1, 0, 0, 95.9, 58.1, 96.5, 39.5, 77.9],\n",
              "       [1, 0, 1, 96.3, 58.5, 91.0, 39.5, 73.5],\n",
              "       [1, 0, 0, 92.5, 56.1, 89.0, 36.0, 72.8],\n",
              "       [1, 0, 1, 94.4, 54.9, 84.0, 34.0, 75.0],\n",
              "       [1, 0, 1, 95.8, 58.5, 91.5, 35.5, 72.3],\n",
              "       [1, 0, 1, 96.0, 59.0, 90.0, 36.0, 73.6],\n",
              "       [1, 0, 0, 90.5, 54.5, 85.0, 35.0, 70.3],\n",
              "       [1, 0, 1, 93.8, 56.8, 87.0, 34.5, 73.2],\n",
              "       [1, 0, 0, 92.8, 56.0, 88.0, 35.0, 74.9],\n",
              "       [1, 0, 0, 92.1, 54.4, 84.0, 33.5, 70.6],\n",
              "       [1, 0, 1, 92.8, 54.1, 93.0, 37.0, 68.0],\n",
              "       [1, 0, 0, 94.3, 56.7, 94.0, 39.0, 74.8],\n",
              "       [1, 0, 1, 91.4, 54.6, 89.0, 37.0, 70.8],\n",
              "       [2, 0, 1, 90.6, 55.7, 85.5, 36.5, 73.1],\n",
              "       [2, 0, 1, 94.4, 57.9, 85.0, 35.5, 71.2],\n",
              "       [2, 0, 1, 93.3, 59.3, 88.0, 35.0, 74.3],\n",
              "       [2, 0, 0, 89.3, 54.8, 82.5, 35.0, 71.2],\n",
              "       [2, 0, 1, 92.4, 56.0, 80.5, 35.5, 68.4],\n",
              "       [2, 0, 0, 84.7, 51.5, 75.0, 34.0, 68.7],\n",
              "       [2, 0, 0, 91.0, 55.0, 84.5, 36.0, 72.8],\n",
              "       [2, 0, 0, 88.4, 57.0, 83.0, 36.5, 68.0],\n",
              "       [2, 0, 1, 85.3, 54.1, 77.0, 32.0, 62.7],\n",
              "       [2, 0, 0, 90.0, 55.5, 81.0, 32.0, 72.0],\n",
              "       [2, 0, 1, 85.1, 51.5, 76.0, 35.5, 70.3],\n",
              "       [2, 0, 1, 90.7, 55.9, 81.0, 34.0, 71.5],\n",
              "       [2, 0, 1, 91.4, 54.4, 84.0, 35.0, 72.8],\n",
              "       [3, 1, 1, 90.1, 54.8, 89.0, 37.5, 66.0],\n",
              "       [3, 1, 1, 98.6, 63.2, 85.0, 34.0, 66.9],\n",
              "       [3, 1, 1, 95.4, 59.2, 85.0, 37.0, 69.0],\n",
              "       [3, 1, 0, 91.6, 56.4, 88.0, 38.0, 65.0],\n",
              "       [3, 1, 0, 95.6, 59.6, 85.0, 36.0, 64.0],\n",
              "       [3, 1, 1, 97.6, 61.0, 93.5, 40.0, 67.9],\n",
              "       [3, 1, 0, 93.1, 58.1, 91.0, 38.0, 67.4],\n",
              "       [4, 1, 1, 96.9, 63.0, 91.5, 43.0, 71.3],\n",
              "       [4, 1, 1, 103.1, 63.2, 92.5, 38.0, 72.5],\n",
              "       [4, 1, 1, 99.9, 61.5, 93.7, 38.0, 68.7],\n",
              "       [4, 1, 0, 95.1, 59.4, 93.0, 41.0, 67.2],\n",
              "       [4, 1, 1, 94.5, 64.2, 91.0, 39.0, 66.5],\n",
              "       [4, 1, 1, 102.5, 62.8, 96.0, 40.0, 73.2],\n",
              "       [4, 1, 0, 91.3, 57.7, 88.0, 39.0, 63.1],\n",
              "       [5, 1, 1, 95.7, 59.0, 86.0, 38.0, 63.1],\n",
              "       [5, 1, 0, 91.3, 58.0, 90.5, 39.0, 65.5],\n",
              "       [5, 1, 0, 92.0, 56.4, 88.5, 38.0, 64.1],\n",
              "       [5, 1, 0, 96.9, 56.5, 89.5, 38.5, 63.0],\n",
              "       [5, 1, 0, 93.5, 57.4, 88.5, 38.0, 68.2],\n",
              "       [5, 1, 0, 90.4, 55.8, 86.0, 36.5, 63.2],\n",
              "       [5, 1, 1, 93.3, 57.6, 85.0, 36.5, 64.7],\n",
              "       [5, 1, 1, 94.1, 56.0, 88.5, 38.0, 65.9],\n",
              "       [5, 1, 1, 98.0, 55.6, 88.0, 37.5, 65.0],\n",
              "       [5, 1, 0, 91.9, 56.4, 87.0, 38.0, 65.4],\n",
              "       [5, 1, 1, 92.8, 57.6, 90.0, 40.0, 65.7],\n",
              "       [5, 1, 1, 85.9, 52.4, 80.5, 35.0, 62.0],\n",
              "       [5, 1, 1, 82.5, 52.3, 82.0, 36.5, 65.7],\n",
              "       [6, 1, 0, 88.7, 52.0, 83.0, 38.0, 61.5],\n",
              "       [6, 1, 1, 93.8, 58.1, 89.0, 38.0, 66.2],\n",
              "       [6, 1, 1, 92.4, 56.8, 89.0, 41.0, 64.5],\n",
              "       [6, 1, 1, 93.6, 56.2, 84.0, 36.0, 62.8],\n",
              "       [6, 1, 1, 86.5, 51.0, 81.0, 36.5, 63.0],\n",
              "       [6, 1, 1, 85.8, 50.0, 81.0, 36.5, 62.8],\n",
              "       [6, 1, 1, 86.7, 52.6, 84.0, 38.0, 62.3],\n",
              "       [6, 1, 1, 90.6, 56.0, 85.5, 38.0, 65.6],\n",
              "       [6, 1, 0, 86.0, 54.0, 82.0, 36.5, 60.7],\n",
              "       [6, 1, 0, 90.0, 53.8, 81.5, 36.0, 62.0],\n",
              "       [6, 1, 1, 88.4, 54.6, 80.5, 36.0, 62.6],\n",
              "       [6, 1, 1, 89.5, 56.2, 92.0, 40.5, 65.6],\n",
              "       [6, 1, 0, 88.2, 53.2, 86.5, 38.5, 60.3],\n",
              "       [7, 1, 1, 98.5, 60.7, 93.0, 41.5, 71.7],\n",
              "       [7, 1, 0, 89.6, 58.0, 87.5, 38.0, 66.7],\n",
              "       [7, 1, 1, 97.7, 58.4, 84.5, 35.0, 64.4],\n",
              "       [7, 1, 1, 92.6, 54.6, 85.0, 38.5, 69.8],\n",
              "       [7, 1, 1, 97.8, 59.6, 89.0, 38.0, 65.5],\n",
              "       [7, 1, 1, 90.7, 56.3, 85.0, 37.0, 67.6],\n",
              "       [7, 1, 1, 89.2, 54.0, 82.0, 38.0, 63.8],\n",
              "       [7, 1, 1, 91.8, 57.6, 84.0, 35.5, 64.2],\n",
              "       [7, 1, 1, 91.6, 56.6, 88.5, 37.5, 64.5],\n",
              "       [7, 1, 1, 94.8, 55.7, 83.0, 38.0, 66.5],\n",
              "       [7, 1, 1, 91.0, 53.1, 86.0, 38.0, 63.8],\n",
              "       [7, 1, 1, 93.2, 68.6, 84.0, 35.0, 65.6],\n",
              "       [7, 1, 0, 93.3, 56.2, 86.5, 38.5, 64.8],\n",
              "       [7, 1, 1, 89.5, 56.0, 81.5, 36.5, 66.0],\n",
              "       [7, 1, 1, 88.6, 54.7, 82.5, 39.0, 64.4],\n",
              "       [7, 1, 0, 92.4, 55.0, 89.0, 38.0, 63.5],\n",
              "       [7, 1, 1, 91.5, 55.2, 82.5, 36.5, 62.9],\n",
              "       [7, 1, 0, 93.6, 59.9, 89.0, 40.0, 67.6]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criando objeto da classe One Hot Encoder\n",
        "# detalhando os valores categoricos das columas convertidas\n",
        "ColumnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [1,2])], remainder = 'passthrough')"
      ],
      "metadata": {
        "id": "hBXORI9jsv_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# atualizando a base de dados previsores\n",
        "previsores = ColumnTransformer.fit_transform(base)"
      ],
      "metadata": {
        "id": "AjYk0aKXs2Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mostrando o numero de linhas\n",
        "len(previsores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Vjxeemr-E4",
        "outputId": "d28ecc0e-3b68-4997-c356-0a6e883aa9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mostrando o numero de colunas\n",
        "len(previsores[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-M30IpUsRDt",
        "outputId": "5455488c-b387-4575-ee43-7df73ff390c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otxUvoYisSE9",
        "outputId": "40ad799d-94da-4b5f-d841-fa275f20ed25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1. ,  0. ,  0. , ..., 89. , 36. , 74.5],\n",
              "       [ 1. ,  0. ,  1. , ..., 91.5, 36.5, 72.5],\n",
              "       [ 1. ,  0. ,  1. , ..., 95.5, 39. , 75.4],\n",
              "       ...,\n",
              "       [ 0. ,  1. ,  1. , ..., 89. , 38. , 63.5],\n",
              "       [ 0. ,  1. ,  0. , ..., 82.5, 36.5, 62.9],\n",
              "       [ 0. ,  1. ,  1. , ..., 89. , 40. , 67.6]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criando a RNA regressor\n",
        "regressor = Sequential()"
      ],
      "metadata": {
        "id": "VOtsmc2htKjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando a primeira camada oculta e a camada de entrada\n",
        "regressor.add(Dense(units = 8, activation = 'relu', input_dim = 11))\n",
        "regressor.add(Dense(units = 8, activation = 'relu'))\n",
        "\n",
        "# criando a camada de saída\n",
        "# função de ativação linear para previsão de numeros\n",
        "regressor.add(Dense(units = 1, activation = 'linear'))"
      ],
      "metadata": {
        "id": "h7-BbMmFtPaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compilação da RNA\n",
        "# funcões loss e metrics especificas para regressão - mean_absolute_error\n",
        "regressor.compile(loss = 'mean_absolute_error', optimizer = 'adam', metrics = ['mean_absolute_error'])"
      ],
      "metadata": {
        "id": "4JYuI-wCuHJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# treinamento da RNA\n",
        "# atualização de pesos a cada 300 registros\n",
        "# repetir 100 vezes\n",
        "regressor.fit(previsores, idade, batch_size = 22, epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNAHHSX5ucgv",
        "outputId": "7be0cd43-810d-41d0-f663-d948989e1307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 6.4304 - mean_absolute_error: 6.4304\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2393 - mean_absolute_error: 4.2393\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.3750 - mean_absolute_error: 2.3750\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5190 - mean_absolute_error: 1.5190\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.6999 - mean_absolute_error: 1.6999\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.7668 - mean_absolute_error: 1.7668\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5194 - mean_absolute_error: 1.5194\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4848 - mean_absolute_error: 1.4848\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5374 - mean_absolute_error: 1.5374\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5290 - mean_absolute_error: 1.5290\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4640 - mean_absolute_error: 1.4640\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4560 - mean_absolute_error: 1.4560\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4594 - mean_absolute_error: 1.4594\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4598 - mean_absolute_error: 1.4598\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4509 - mean_absolute_error: 1.4509\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.4599 - mean_absolute_error: 1.4599\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4514 - mean_absolute_error: 1.4514\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4522 - mean_absolute_error: 1.4522\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4450 - mean_absolute_error: 1.4450\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4405 - mean_absolute_error: 1.4405\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4387 - mean_absolute_error: 1.4387\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4400 - mean_absolute_error: 1.4400\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4331 - mean_absolute_error: 1.4331\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4328 - mean_absolute_error: 1.4328\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4327 - mean_absolute_error: 1.4327\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4354 - mean_absolute_error: 1.4354\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4342 - mean_absolute_error: 1.4342\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4199 - mean_absolute_error: 1.4199\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4246 - mean_absolute_error: 1.4246\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4280 - mean_absolute_error: 1.4280\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4287 - mean_absolute_error: 1.4287\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4151 - mean_absolute_error: 1.4151\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4114 - mean_absolute_error: 1.4114\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4122 - mean_absolute_error: 1.4122\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4094 - mean_absolute_error: 1.4094\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4077 - mean_absolute_error: 1.4077\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4026 - mean_absolute_error: 1.4026\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4002 - mean_absolute_error: 1.4002\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3973 - mean_absolute_error: 1.3973\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4002 - mean_absolute_error: 1.4002\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.3926 - mean_absolute_error: 1.3926\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4076 - mean_absolute_error: 1.4076\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4007 - mean_absolute_error: 1.4007\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.3865 - mean_absolute_error: 1.3865\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3885 - mean_absolute_error: 1.3885\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3909 - mean_absolute_error: 1.3909\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3805 - mean_absolute_error: 1.3805\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3777 - mean_absolute_error: 1.3777\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.3761 - mean_absolute_error: 1.3761\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3761 - mean_absolute_error: 1.3761\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3838 - mean_absolute_error: 1.3838\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3781 - mean_absolute_error: 1.3781\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3720 - mean_absolute_error: 1.3720\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3717 - mean_absolute_error: 1.3717\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3587 - mean_absolute_error: 1.3587\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3527 - mean_absolute_error: 1.3527\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3501 - mean_absolute_error: 1.3501\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3465 - mean_absolute_error: 1.3465\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3548 - mean_absolute_error: 1.3548\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3523 - mean_absolute_error: 1.3523\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3396 - mean_absolute_error: 1.3396\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3464 - mean_absolute_error: 1.3464\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3314 - mean_absolute_error: 1.3314\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3483 - mean_absolute_error: 1.3483\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3340 - mean_absolute_error: 1.3340\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3632 - mean_absolute_error: 1.3632\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3360 - mean_absolute_error: 1.3360\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3352 - mean_absolute_error: 1.3352\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3297 - mean_absolute_error: 1.3297\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3164 - mean_absolute_error: 1.3164\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3233 - mean_absolute_error: 1.3233\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3176 - mean_absolute_error: 1.3176\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3185 - mean_absolute_error: 1.3185\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3129 - mean_absolute_error: 1.3129\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3032 - mean_absolute_error: 1.3032\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2938 - mean_absolute_error: 1.2938\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2921 - mean_absolute_error: 1.2921\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2867 - mean_absolute_error: 1.2867\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2730 - mean_absolute_error: 1.2730\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2758 - mean_absolute_error: 1.2758\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2646 - mean_absolute_error: 1.2646\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2583 - mean_absolute_error: 1.2583\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2535 - mean_absolute_error: 1.2535\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2494 - mean_absolute_error: 1.2494\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2399 - mean_absolute_error: 1.2399\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2435 - mean_absolute_error: 1.2435\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2447 - mean_absolute_error: 1.2447\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2211 - mean_absolute_error: 1.2211\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2128 - mean_absolute_error: 1.2128\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2100 - mean_absolute_error: 1.2100\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2001 - mean_absolute_error: 1.2001\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1918 - mean_absolute_error: 1.1918\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1907 - mean_absolute_error: 1.1907\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1815 - mean_absolute_error: 1.1815\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1720 - mean_absolute_error: 1.1720\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1626 - mean_absolute_error: 1.1626\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1487 - mean_absolute_error: 1.1487\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1487 - mean_absolute_error: 1.1487\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1516 - mean_absolute_error: 1.1516\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1406 - mean_absolute_error: 1.1406\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1232 - mean_absolute_error: 1.1232\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1164 - mean_absolute_error: 1.1164\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0990 - mean_absolute_error: 1.0990\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1197 - mean_absolute_error: 1.1197\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0766 - mean_absolute_error: 1.0766\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1016 - mean_absolute_error: 1.1016\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0737 - mean_absolute_error: 1.0737\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0609 - mean_absolute_error: 1.0609\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0615 - mean_absolute_error: 1.0615\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0533 - mean_absolute_error: 1.0533\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0279 - mean_absolute_error: 1.0279\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0071 - mean_absolute_error: 1.0071\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0226 - mean_absolute_error: 1.0226\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9943 - mean_absolute_error: 0.9943\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9874 - mean_absolute_error: 0.9874\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9751 - mean_absolute_error: 0.9751\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9574 - mean_absolute_error: 0.9574\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9640 - mean_absolute_error: 0.9640\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9553 - mean_absolute_error: 0.9553\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9944 - mean_absolute_error: 0.9944\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9442 - mean_absolute_error: 0.9442\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9479 - mean_absolute_error: 0.9479\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9008 - mean_absolute_error: 0.9008\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8893 - mean_absolute_error: 0.8893\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8723 - mean_absolute_error: 0.8723\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8774 - mean_absolute_error: 0.8774\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9171 - mean_absolute_error: 0.9171\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8743 - mean_absolute_error: 0.8743\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8580 - mean_absolute_error: 0.8580\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8272 - mean_absolute_error: 0.8272\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8153 - mean_absolute_error: 0.8153\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7976 - mean_absolute_error: 0.7976\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7828 - mean_absolute_error: 0.7828\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7832 - mean_absolute_error: 0.7832\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7640 - mean_absolute_error: 0.7640\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7635 - mean_absolute_error: 0.7635\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7412 - mean_absolute_error: 0.7412\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7500 - mean_absolute_error: 0.7500\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7951 - mean_absolute_error: 0.7951\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8220 - mean_absolute_error: 0.8220\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6965 - mean_absolute_error: 0.6965\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7184 - mean_absolute_error: 0.7184\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6768 - mean_absolute_error: 0.6768\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6874 - mean_absolute_error: 0.6874\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6618 - mean_absolute_error: 0.6618\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6342 - mean_absolute_error: 0.6342\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6364 - mean_absolute_error: 0.6364\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6265 - mean_absolute_error: 0.6265\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6038 - mean_absolute_error: 0.6038\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5917 - mean_absolute_error: 0.5917\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5909 - mean_absolute_error: 0.5909\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5779 - mean_absolute_error: 0.5779\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5587 - mean_absolute_error: 0.5587\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5680 - mean_absolute_error: 0.5680\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5409 - mean_absolute_error: 0.5409\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5291 - mean_absolute_error: 0.5291\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5347 - mean_absolute_error: 0.5347\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5050 - mean_absolute_error: 0.5050\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5118 - mean_absolute_error: 0.5118\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5399 - mean_absolute_error: 0.5399\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5114 - mean_absolute_error: 0.5114\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4821 - mean_absolute_error: 0.4821\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4699 - mean_absolute_error: 0.4699\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4797 - mean_absolute_error: 0.4797\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4928 - mean_absolute_error: 0.4928\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4878 - mean_absolute_error: 0.4878\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4811 - mean_absolute_error: 0.4811\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4635 - mean_absolute_error: 0.4635\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4509 - mean_absolute_error: 0.4509\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4368 - mean_absolute_error: 0.4368\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4529 - mean_absolute_error: 0.4529\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4461 - mean_absolute_error: 0.4461\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4631 - mean_absolute_error: 0.4631\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4671 - mean_absolute_error: 0.4671\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4498 - mean_absolute_error: 0.4498\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4614 - mean_absolute_error: 0.4614\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4073 - mean_absolute_error: 0.4073\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4286 - mean_absolute_error: 0.4286\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4316 - mean_absolute_error: 0.4316\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4436 - mean_absolute_error: 0.4436\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4176 - mean_absolute_error: 0.4176\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4003 - mean_absolute_error: 0.4003\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3912 - mean_absolute_error: 0.3912\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3941 - mean_absolute_error: 0.3941\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4112 - mean_absolute_error: 0.4112\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3831 - mean_absolute_error: 0.3831\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3701 - mean_absolute_error: 0.3701\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3751 - mean_absolute_error: 0.3751\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3770 - mean_absolute_error: 0.3770\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3664 - mean_absolute_error: 0.3664\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3876 - mean_absolute_error: 0.3876\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3965 - mean_absolute_error: 0.3965\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4311 - mean_absolute_error: 0.4311\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4055 - mean_absolute_error: 0.4055\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3611 - mean_absolute_error: 0.3611\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3452 - mean_absolute_error: 0.3452\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3471 - mean_absolute_error: 0.3471\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3415 - mean_absolute_error: 0.3415\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3801 - mean_absolute_error: 0.3801\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3410 - mean_absolute_error: 0.3410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f111010d5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes = regressor.predict(previsores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rXnv61Euike",
        "outputId": "e15c8013-2d2a-484a-fa33-5a93c3c3e0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando as médias dos preços previstos\n",
        "prev = previsoes.mean()\n",
        "prev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w19rxgTu1MV",
        "outputId": "0f1d008a-27d8-42f2-b74c-96d76b59dfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.6910505"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando as médias dos preços existentes\n",
        "idade_real = idade.mean()\n",
        "idade_real"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8nQ5clZu-l5",
        "outputId": "ff09f906-b559-4995-b018-ea6252ebdc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.8173076923076925"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prec = abs(((prev / idade_real) - 1) * 100)\n",
        "print(prec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHIcLz7kvBuN",
        "outputId": "1a707830-f77a-4437-a22f-814e39fc7e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.307492426720915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O que foi feito:\n",
        "**Remoção das colunas:**  'case', 'earconch', 'eye', 'chest', 'belly';\n",
        "#####**Valores Nulos:** em 'age' e 'footlgth' foram identificados valores nulos que foram preenchidos com a mediana;"
      ],
      "metadata": {
        "id": "yz1Hbd6Hvvmy"
      }
    }
  ]
}